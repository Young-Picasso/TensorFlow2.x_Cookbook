{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to reimplement the MNIST model from *The Introductory CNN Model* recipe in chapter 8 for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Reimplement the MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Padding the images by 2 pixels since in the paper input images were 32x32\n",
    "x_train = np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "x_test = np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "# Normalize\n",
    "x_train = x_train / 255\n",
    "x_test = x_test/ 255\n",
    "\n",
    "# Set model parameters\n",
    "image_width = x_train[0].shape[0]\n",
    "image_height = x_train[0].shape[1]\n",
    "num_channels = 1 # grayscale = 1 channel\n",
    "\n",
    "# Training and Test data variables\n",
    "batch_size = 100\n",
    "evaluation_size = 500\n",
    "generations = 300\n",
    "eval_every = 5\n",
    "\n",
    "# Set for reproducible results\n",
    "seed = 98\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Declare the model\n",
    "input_data = tf.keras.Input(dtype=tf.float32, shape=(image_width,image_height, num_channels), name=\"INPUT\")\n",
    "\n",
    "# First Conv-ReLU-MaxPool Layer\n",
    "conv1 = tf.keras.layers.Conv2D(filters=6,\n",
    "                               kernel_size=5,\n",
    "                               padding='VALID',\n",
    "                               activation=\"relu\",\n",
    "                               name=\"C1\")(input_data)\n",
    "\n",
    "max_pool1 = tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                                      strides=2, \n",
    "                                      padding='SAME',\n",
    "                                      name=\"S1\")(conv1)\n",
    "\n",
    "# Second Conv-ReLU-MaxPool Layer\n",
    "conv2 = tf.keras.layers.Conv2D(filters=16,\n",
    "                               kernel_size=5,\n",
    "                               padding='VALID',\n",
    "                               strides=1,\n",
    "                               activation=\"relu\",\n",
    "                               name=\"C3\")(max_pool1)\n",
    "\n",
    "max_pool2 = tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                                      strides=2, \n",
    "                                      padding='SAME',\n",
    "                                      name=\"S4\")(conv2)\n",
    "\n",
    "# Flatten Layer\n",
    "flatten = tf.keras.layers.Flatten(name=\"FLATTEN\")(max_pool2)\n",
    "\n",
    "\n",
    "# First Fully Connected Layer\n",
    "fully_connected1 = tf.keras.layers.Dense(units=120,\n",
    "                                         activation=\"relu\",\n",
    "                                         name=\"F5\")(flatten)\n",
    "\n",
    "# Second Fully Connected Layer\n",
    "fully_connected2 = tf.keras.layers.Dense(units=84,\n",
    "                                         activation=\"relu\",\n",
    "                                         name=\"F6\")(fully_connected1)\n",
    "\n",
    "# Final Fully Connected Layer\n",
    "final_model_output = tf.keras.layers.Dense(units=10,\n",
    "                                           activation=\"softmax\",\n",
    "                                           name=\"OUTPUT\"\n",
    "                                           )(fully_connected2)\n",
    "    \n",
    "\n",
    "model = tf.keras.Model(inputs= input_data, outputs=final_model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We now compile the model with sparse categorical cross-entropy loss and the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "S1 (MaxPooling2D)            (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "S4 (MaxPooling2D)            (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "FLATTEN (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "F5 (Dense)                   (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "F6 (Dense)                   (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We can now create a timestamped subdirectory for each run. The summary writer will write the TensorBoard logs to this folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"logs/experiment-\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. We instantiate the TensorBoard callback and pass it to the fit method. All the logs during the training phase will be stored in this directory and can be viewed instantly in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0420 - val_accuracy: 0.9871\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.0325 - val_accuracy: 0.9899\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0338 - val_accuracy: 0.9892\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.0341 - val_accuracy: 0.9900\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0396 - val_accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fec53fc5cf8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, write_images=True, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train,\n",
    "          y=y_train,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now we start the TensorBoard application by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7f25330176128ffb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7f25330176128ffb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir='logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While TensorBoard seems like a useful tool, this in-notebook version is a bit clunky/unyieldy. It would be interesting to take a deep dive into the applications of this tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py365",
   "language": "python",
   "name": "py365"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
