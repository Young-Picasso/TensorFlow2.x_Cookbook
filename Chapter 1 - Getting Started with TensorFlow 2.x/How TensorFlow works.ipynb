{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "283580b3",
   "metadata": {},
   "source": [
    "## 1. Import or generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ceee22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 17:02:46.965407: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 4.44 KiB (download: 4.44 KiB, generated: Unknown size, total: 4.44 KiB) to /home/wil/tensorflow_datasets/iris/2.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd9d17d9e204b3c8c7bf21b3b940c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2932628d435f4aad82de028f876a4ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling iris-train.tfrecord...:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset iris downloaded and prepared to /home/wil/tensorflow_datasets/iris/2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 17:02:48.176550: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-17 17:02:48.250768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.251133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-01-17 17:02:48.251147: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-17 17:02:48.260132: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-17 17:02:48.260162: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-17 17:02:48.264583: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-17 17:02:48.266853: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-17 17:02:48.274663: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-01-17 17:02:48.276918: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-17 17:02:48.277756: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-17 17:02:48.277840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.278226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.278778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-01-17 17:02:48.279354: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-17 17:02:48.280061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.280403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:2d:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.785GHz coreCount: 40 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-01-17 17:02:48.280442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.280786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.281318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-01-17 17:02:48.281576: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-17 17:02:48.859488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-17 17:02:48.859509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-01-17 17:02:48.859514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-01-17 17:02:48.859708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.860093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.860432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-17 17:02:48.860802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6223 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "data = tfds.load(\"iris\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daab508",
   "metadata": {},
   "source": [
    "## 2. Transform and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d25251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that while the book describes this process, step 4 is required to define batch_size first.\n",
    "for batch in data.batch(batch_size, drop_remainder=True):\n",
    "    labels = tf.one_hot(batch['label'], 3)\n",
    "    X = batch['features']\n",
    "    X = (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa39566",
   "metadata": {},
   "source": [
    "## 3. Partition the dataset into training, test, and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53803252",
   "metadata": {},
   "source": [
    "We generally want to test our algorithms on different sets that we have trained on. Many algorithms also require hyperparameter tuning, so we set aside a validation set for determining the best set of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f9866f",
   "metadata": {},
   "source": [
    "## 4. Set algorithm parameters (hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3897c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 32\n",
    "input_size = 4\n",
    "output_size = 3\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bf465",
   "metadata": {},
   "source": [
    "## 5. Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f80895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random.normal(shape=(input_size, output_size), dtype=tf.float32))\n",
    "biases = tf.Variable(tf.random.normal(shape=(output_size,), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceab6a5",
   "metadata": {},
   "source": [
    "## 6. Define the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "842d91eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 17:14:23.988010: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-17 17:14:24.470760: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    }
   ],
   "source": [
    "logits = tf.add(tf.matmul(X, weights), biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de22bf",
   "metadata": {},
   "source": [
    "## 7. Declare the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79981ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6e8ad",
   "metadata": {},
   "source": [
    "## 8. Initialize and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be86aaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    logits = tf.add(tf.matmul(X, weights), biases)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels, logits))\n",
    "gradients = tape.gradient(loss, [weights, biases])\n",
    "optimizer.apply_gradients(zip(gradients, [weights, biases]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c5b39",
   "metadata": {},
   "source": [
    "## 9. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe4e78ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss is 1.521\n",
      "real label: 0, fitted: 2\n",
      "real label: 1, fitted: 2\n",
      "real label: 1, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 0, fitted: 1\n",
      "real label: 2, fitted: 2\n",
      "real label: 1, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 1, fitted: 2\n",
      "real label: 0, fitted: 1\n",
      "real label: 1, fitted: 2\n",
      "real label: 0, fitted: 1\n",
      "real label: 2, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 0, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 0, fitted: 2\n",
      "real label: 1, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 0, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 1, fitted: 2\n",
      "real label: 0, fitted: 1\n",
      "real label: 0, fitted: 1\n",
      "real label: 2, fitted: 2\n",
      "real label: 0, fitted: 1\n",
      "real label: 1, fitted: 2\n",
      "real label: 2, fitted: 2\n",
      "real label: 0, fitted: 2\n",
      "real label: 2, fitted: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"final loss is {loss.numpy():.3f}\")\n",
    "preds = tf.math.argmax(tf.add(tf.matmul(X, weights), biases), axis=1)\n",
    "ground_truth = tf.math.argmax(labels, axis=1)\n",
    "for y_true, y_pred in zip(ground_truth.numpy(), preds.numpy()):\n",
    "    print(f\"real label: {y_true}, fitted: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59311986",
   "metadata": {},
   "source": [
    "## 10. Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6122a3",
   "metadata": {},
   "source": [
    "Most of the time, we will want to go back and change some of the hyperparameters, checking the models performance based on our tests. We then repeat the previous steps with different hyperparameters and evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f06261",
   "metadata": {},
   "source": [
    "## 11. Deploy/predict new outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4fb063",
   "metadata": {},
   "source": [
    "It is also a key requirement to know how to make predictions on new and unseen data. We can achieve this easily with TensorFlow with all of our models once we have them trained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
